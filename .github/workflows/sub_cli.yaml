# This workflow is a reusable one called by other workflows
name: (template) Elemental E2E single cluster CLI tests

on:
  workflow_call:
    # Variables to set when calling this reusable workflow
    inputs:
      backup_restore_version:
        required: true
        type: string
      boot_type:
        required: true
        type: string
      ca_type:
        required: true
        type: string
      cert-manager_version:
        required: true
        type: string
      cluster_name:
        required: true
        type: string
      cluster_namespace:
        required: true
        type: string
      cluster_type:
        required: true
        type: string
      destroy_runner:
        required: true
        type: boolean
      force_downgrade:
        required: true
        type: boolean
      full_backup_restore:
        required: true
        type: boolean
      k8s_downstream_version:
        required: true
        type: string
      k8s_upstream_version:
        required: true
        type: string
      node_number:
        required: true
        type: string
      operator_install_type:
        required: true
        type: string
      operator_repo:
        required: true
        type: string
      operator_upgrade:
        required: true
        type: string
      os_to_test:
        required: true
        type: string
      public_domain:
        required: true
        type: string
      public_fqdn:
        required: true
        type: string
      qase_project_code:
        required: true
        type: string
      qase_run_id:
        required: true
        type: string
      rancher_version:
        required: true
        type: string
      rancher_upgrade:
        required: true
        type: string
      reset:
        required: true
        type: boolean
      runner_label:
        required: true
        type: string
      selinux:
        required: true
        type: boolean
      sequential:
        required: true
        type: boolean
      snap_type:
        required: true
        type: string
      test_type:
        required: true
        type: string
      upgrade_image:
        required: true
        type: string
      upgrade_os_channel:
        required: true
        type: string
      upgrade_type:
        required: true
        type: string

    # Job outputs to export for caller workflow
    outputs:
      steps_status:
        description: Status of the executed test jobs
        value: ${{ jobs.cli.outputs.steps_status }}

    # Variables to set when calling this reusable workflow
    secrets:
      qase_api_token:

jobs:
  cli:
    runs-on: ${{ inputs.runner_label }}
    outputs:
      # For this to work 'id:' in steps are mandatory!
      steps_status: ${{ join(steps.*.conclusion, ' ') }}
    env:
      CERT_MANAGER_VERSION: ${{ inputs.cert-manager_version }}
      CLUSTER_NAME: ${{ inputs.cluster_name }}
      CLUSTER_NS: ${{ inputs.cluster_namespace }}
      CLUSTER_TYPE: ${{ inputs.cluster_type }}
      # QASE variables
      QASE_API_TOKEN: ${{ secrets.qase_api_token }}
      QASE_PROJECT_CODE: ${{ inputs.qase_project_code }}
      QASE_RUN_ID: ${{ inputs.qase_run_id }}
      # K3S / RKE2 flags to use for installation
      INSTALL_K3S_SKIP_ENABLE: true
      INSTALL_K3S_VERSION: ${{ inputs.k8s_upstream_version }}
      INSTALL_RKE2_VERSION: ${{ inputs.k8s_upstream_version }}
      K3S_KUBECONFIG_MODE: 0644
      # Distribution to use to host Rancher Manager (K3s or RKE2)
      K8S_UPSTREAM_VERSION: ${{ inputs.k8s_upstream_version }}
      # For K8s cluster to provision with Rancher Manager
      K8S_DOWNSTREAM_VERSION: ${{ inputs.k8s_downstream_version }}
      OPERATOR_INSTALL_TYPE: ${{ inputs.operator_install_type }}
      OS_TO_TEST: ${{ inputs.os_to_test }}
      # For Rancher Manager
      RANCHER_VERSION: ${{ inputs.rancher_version }}
      SELINUX: ${{ inputs.selinux }}
      TEST_TYPE: ${{ inputs.test_type }}
      TIMEOUT_SCALE: 3
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4

      - name: Setup Go
        id: setup_go
        uses: actions/setup-go@v5
        with:
          cache-dependency-path: tests/go.sum
          go-version-file: tests/go.mod

      - name: Define needed system variables
        id: define_sys_vars
        run: |
          # Add missing PATH, removed in recent distributions for security reasons...
          echo "/usr/local/bin" >> ${GITHUB_PATH}

      - name: Install Rancher Manager and Elemental
        id: install_rancher_elemental
        env:
          CA_TYPE: ${{ inputs.ca_type }}
          OPERATOR_REPO: ${{ inputs.operator_repo }}
          PUBLIC_FQDN: ${{ inputs.public_fqdn }}
          PUBLIC_DOMAIN: ${{ inputs.public_domain }}
        run: cd tests && make e2e-install-rancher

      - name: Install backup-restore components
        id: install_backup_restore
        env:
          BACKUP_RESTORE_VERSION: ${{ inputs.backup_restore_version }}
        run: cd tests && make e2e-install-backup-restore

      - name: Extract component versions/informations
        id: component
        run: |
          # Extract rancher-backup-operator version
          BACKUP_OPERATOR_VERSION=$(kubectl get pod \
                                     --namespace cattle-resources-system \
                                     -l app.kubernetes.io/name=rancher-backup \
                                     -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

          # Extract CertManager version
          CERT_MANAGER_VERSION=$(kubectl get pod \
                                   --namespace cert-manager \
                                   -l app=cert-manager \
                                   -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

          # Extract elemental-operator version
          OPERATOR_VERSION=$(kubectl get pod \
                               --namespace cattle-elemental-system \
                               -l app=elemental-operator \
                               -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

          # Extract Rancher Manager version
          RANCHER_VERSION=$(kubectl get pod \
                              --namespace cattle-system \
                              -l app=rancher \
                              -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

          # Export values
          echo "backup_operator_version=${BACKUP_OPERATOR_VERSION}" >> ${GITHUB_OUTPUT}
          echo "cert_manager_version=${CERT_MANAGER_VERSION}" >> ${GITHUB_OUTPUT}
          echo "operator_version=${OPERATOR_VERSION}" >> ${GITHUB_OUTPUT}
          echo "rancher_image_version=${RANCHER_VERSION}" >> ${GITHUB_OUTPUT}

      - name: Configure Rancher and Libvirt
        id: configure_rancher
        env:
          SNAP_TYPE: ${{ inputs.snap_type }}
        run: cd tests && make e2e-configure-rancher

      - name: Create ISO image for master pool
        id: create_iso_master
        env:
          EMULATE_TPM: true
          POOL: master
        run: |
          # Only use ISO boot if the upstream cluster is RKE2
          # due to issue with pxe, dhcp traffic
          if ${{ contains(inputs.k8s_upstream_version, 'rke') }}; then
            export BOOT_TYPE=iso
          fi
          cd tests && make e2e-iso-image

      - name: Extract iPXE artifacts from ISO
        id: extract_ipxe_artifacts
        if: ${{ inputs.boot_type == 'pxe' }}
        run: cd tests && make extract_kernel_init_squash && make ipxe

      - name: Bootstrap node 1, 2 and 3 in pool "master" (use Emulated TPM if possible)
        id: bootstrap_master_nodes
        env:
          EMULATE_TPM: true
          POOL: master
          VM_START: 1
          VM_END: 3
        run: |
          # Only use ISO boot if the upstream cluster is RKE2
          # due to issue with pxe, dhcp traffic
          # Set RAM to 10GB for RKE2 and vCPU to 6, a bit more than the recommended values
          if ${{ contains(inputs.k8s_upstream_version, 'rke') }}; then
            export BOOT_TYPE=iso
            export VM_MEM=10240
            export VM_CPU=6
          fi

          # Execute bootstrapping test
          if ${{ inputs.sequential == true }}; then
            # Force node bootstrapping in sequential instead of parallel
            cd tests
            for ((i = VM_START ; i <= VM_END ; i++)); do
              VM_INDEX=${i} make e2e-bootstrap-node
            done
          else
            cd tests && VM_INDEX=${VM_START} VM_NUMBERS=${VM_END} make e2e-bootstrap-node
          fi

      - name: Install a simple application
        id: install_simple_app
        run: cd tests && make e2e-install-app && make e2e-check-app

      - name: Reset a node in the cluster
        id: reset_node
        if: ${{ inputs.reset == true }}
        run: cd tests && make e2e-reset && make e2e-check-app

      - name: Upgrade Elemental Operator
        id: operator_upgrade
        if: ${{ inputs.operator_upgrade != '' }}
        env:
          OPERATOR_UPGRADE: ${{ inputs.operator_upgrade }}
        run: |
          cd tests

          if make e2e-upgrade-operator; then
            # Extract elemental-operator version
            OPERATOR_VERSION=$(kubectl get pod \
                               --namespace cattle-elemental-system \
                               -l app=elemental-operator \
                               -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

            # Export values
            echo "operator_upgrade=${OPERATOR_UPGRADE}" >> ${GITHUB_OUTPUT}
            echo "operator_version=${OPERATOR_VERSION}" >> ${GITHUB_OUTPUT}

            # Check application
            make e2e-check-app
          else
            # Needed to be sure that Github Action will see the failure
            false
          fi

      - name: Upgrade Rancher Manager
        id: rancher_upgrade
        if: ${{ inputs.rancher_upgrade != '' }}
        env:
          CA_TYPE: ${{ inputs.ca_type }}
          PUBLIC_FQDN: ${{ inputs.public_fqdn }}
          PUBLIC_DOMAIN: ${{ inputs.public_domain }}
          RANCHER_UPGRADE: ${{ inputs.rancher_upgrade }}
        run: |
          cd tests

          if make e2e-upgrade-rancher-manager; then
            # Extract Rancher Manager version
            RANCHER_VERSION=$(kubectl get pod \
                                --namespace cattle-system \
                                -l app=rancher \
                                -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

            # Export values
            echo "rancher_image_version=${RANCHER_VERSION}" >> ${GITHUB_OUTPUT}

            # Check application
            make e2e-check-app
          else
            # Needed to be sure that Github Action will see the failure
            false
          fi

      - name: Upgrade node 1 to specified OS version with osImage
        id: upgrade_node_1
        if: ${{ inputs.upgrade_image != '' }}
        env:
          FORCE_DOWNGRADE: ${{ inputs.force_downgrade }}
          UPGRADE_IMAGE: ${{ inputs.upgrade_image }}
          UPGRADE_TYPE: osImage
          VM_INDEX: 1
        run: |
          cd tests && make e2e-upgrade-node && make e2e-check-app

      - name: Upgrade other nodes to specified OS version with osImage
        id: upgrade_other_nodes_osimage
        if: ${{ inputs.upgrade_image != '' && inputs.upgrade_os_channel == ''}}
        env:
          FORCE_DOWNGRADE: ${{ inputs.force_downgrade }}
          UPGRADE_IMAGE: ${{ inputs.upgrade_image }}
          UPGRADE_TYPE: osImage
          VM_INDEX: 2
          VM_NUMBERS: 3
        run: |
          cd tests && make e2e-upgrade-node && make e2e-check-app

      - name: Upgrade other nodes to specified OS version with managedOSVersionName
        id: upgrade_other_nodes_managedosversionname
        if: ${{ inputs.upgrade_os_channel != '' }}
        env:
          FORCE_DOWNGRADE: ${{ inputs.force_downgrade }}
          UPGRADE_OS_CHANNEL: ${{ inputs.upgrade_os_channel }}
          UPGRADE_TYPE: managedOSVersionName
          VM_INDEX: 2
          VM_NUMBERS: 3
        run: |
          cd tests && make e2e-upgrade-node && make e2e-check-app

      - name: Extract ISO version
        id: iso_version
        if: ${{ always() }}
        run: |
          # Extract OS version from ISO
          ISO=$(file -Ls *.iso 2>/dev/null | awk -F':' '/boot sector/ { print $1 }')
          if [[ -n "${ISO}" ]]; then
            # NOTE: always keep 'initrd' at the end, as there is always a link with this name
            for INITRD_NAME in elemental.initrd* initrd; do
              INITRD_FILE=$(isoinfo -i ${ISO} -R -find -type f -name ${INITRD_NAME} -print 2>/dev/null)
              if [[ -n "${INITRD_FILE}" ]]; then
                isoinfo -i ${ISO} -R -x ${INITRD_FILE} 2>/dev/null \
                  | xz -dc \
                  | cpio -i --to-stdout usr/lib/initrd-release > os-release
                eval $(grep IMAGE_TAG os-release 2>/dev/null)

                # We found an initrd, stop here
                break
              fi
            done
          fi

          # Export value (even if empty!)
          echo "os_version=${IMAGE_TAG}" >> ${GITHUB_OUTPUT}

      - name: Remove old built ISO image
        id: clean_master_iso
        # Only one at a time is allowed, the new one will be created after if needed
        run: rm -f *.iso

      - name: Create ISO image for worker pool
        id: create_iso_worker
        if: ${{ inputs.node_number > 3 }}
        env:
          BOOT_TYPE: iso
          POOL: worker
        run: cd tests && make e2e-iso-image

      - name: Bootstrap additional nodes in pool "worker" (total of ${{ inputs.node_number }})
        id: bootstrap_worker_nodes
        if: ${{ inputs.node_number > 3 }}
        env:
          BOOT_TYPE: iso
          POOL: worker
          VM_START: 4
          VM_END: ${{ inputs.node_number }}
        run: |
          # Set RAM to 10GB for RKE2 and vCPU to 6, a bit more than the recommended values
          if ${{ contains(inputs.k8s_upstream_version, 'rke') }}; then
            export VM_MEM=10240
            export VM_CPU=6
          fi

          cd tests
          if ${{ inputs.sequential == true }}; then
            # Force node bootstrapping in sequential instead of parallel
            for ((i = VM_START ; i <= VM_END ; i++)); do
              VM_INDEX=${i} make e2e-bootstrap-node
            done
          else
            VM_INDEX=${VM_START} VM_NUMBERS=${VM_END} make e2e-bootstrap-node
          fi

          # Check the installed application
          make e2e-check-app

      - name: Uninstall Elemental Operator
        id: uninstall_elemental_operator
        env:
          OPERATOR_REPO: ${{ inputs.operator_repo }}
        # Don't test Operator uninstall if we want to keep the runner for debugging purposes
        if: ${{ inputs.destroy_runner == true }}
        run: cd tests && make e2e-uninstall-operator

      # This step must be called in each worklow that wants a summary!
      - name: Get logs and add summary
        id: logs_summary
        if: ${{ always() }}
        uses: ./.github/actions/logs-and-summary
        with:
          backup_operator_version: ${{ steps.component.outputs.backup_operator_version }}
          ca_type: ${{ inputs.ca_type }}
          cert_manager_version: ${{ steps.component.outputs.cert_manager_version }}
          cluster_type: ${{ inputs.cluster_type }}
          k8s_downstream_version: ${{ inputs.k8s_downstream_version }}
          k8s_upstream_version: ${{ inputs.k8s_upstream_version }}
          node_number: ${{ inputs.node_number }}
          operator_upgrade: ${{ steps.operator_upgrade.outputs.operator_upgrade }}
          operator_version: ${{ steps.component.outputs.operator_version }}
          operator_version_upgrade: ${{ steps.operator_upgrade.outputs.operator_version }}
          os_to_test: ${{ inputs.os_to_test }}
          os_version: ${{ steps.iso_version.outputs.os_version }}
          public_fqdn: ${{ inputs.public_fqdn }}
          rancher_image_version: ${{ steps.component.outputs.rancher_image_version }}
          rancher_image_version_upgrade: ${{ steps.rancher_upgrade.outputs.rancher_image_version }}
          rancher_upgrade: ${{ inputs.rancher_upgrade }}
          rancher_version: ${{ inputs.rancher_version }}
          sequential: ${{ inputs.sequential }}
          snap_type: ${{ inputs.snap_type }}
          steps_status: ${{ join(steps.*.conclusion, ' ') }}
          test_type: ${{ inputs.test_type }}
          upgrade_image: ${{ inputs.upgrade_image }}
          upgrade_os_channel: ${{ inputs.upgrade_os_channel }}
